{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Neural Network을 감성분석에 적용하기\n",
    "### Dr. Seong-K. Park@ai-khwarizmi.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 요약 정리\n",
    "\n",
    "<p>\n",
    "인터넷과 소셜 미디어 시대에 사람들의 견해와 리뷰, 추천은 정치나 비지니스에 상당히 중요한 자원이 되고있습니다. 현대 기술에 감사하게도 이제 우리는 이런 데이터를 대단히 효율적으로 수집하고 분석할 수 있는 기술이 생겼습니다. 이번 장에서는 감성분석이라고 불리는 자연어 처리(Natural Language Processing, NLP)의 상세 영역까지 들어가서 문서를 분류하기 위한 자연어 처리(NLP) 를 위한 컨볼류션알고리즘의 사용법을 설명합니다.</p>\n",
    "\n",
    "<p>최근에 많은 애플리케이션에서 사용하는 데이터가 있는가 있는데, 바로 텍스트입니다. 스팸 메일 분류를 예로 들면, 이메일의 내용에 이 분류 작업에 필요한 중요한 정보가 들어 있습니다. 또는 이민 정책에 관한 정치인의 의견을 분석해야 할 때 각자의 언행이나 트윗이 중요한 정보를 제공합니다. 고객 서비스에서는 메시지가 불만사항인지 문의사항인지를 구분해야 할 때가 많습니다. 메시지의 제목이나 내용으로 고객의 의도를 자동으로 파악해서 적절한 부서로 전달하거나, 완전히 자동으로 응답할 수 도 있습니다.</p>\n",
    "\n",
    "<p>\n",
    "이번 장에서는 인터넷 영화 자료(Internet Movie Database, IMDb)의 영화 리뷰 데이터로 작업을 할 것이다. 이 데이터는 매스 등에(Mass et al.)의해 수집되었다. 영화 리뷰 데이터는 5만 개로 양이나 음으로 레이블된 양극의 영화 리뷰로 구성되어 있다(여기서, 별 6개이상은 양(+) 그리고 아니면 음(-)). 다음 절에서는 이러한 영화 리뷰의 부분집합에서 의미 있는 축출하여 특정 리뷰어가 영화에 대해 좋다고 하는지 싫다고 하는지를 예측할 수 있는 머신러닝 모델을 만드는 방법에 대해 학습한다.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "영화 리뷰 데이터의 압축된 아카이브(84.1MB) 다운로드 장소: http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz \n",
    "<br>\n",
    "데이터를 성공적으로 추출했다면 압축이 풀린 다운로드 아카이브에서 하나의 CSV 파일로 개별 텍스트 문서들을 병합하겠습니다.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  sentiment\n",
      "0  On MTV cribs all the ballers and shot callers ...          1\n",
      "1  This film is really ONLY Bill Maher's interpre...          0\n",
      "2  On the scale of 1 to 10, I gave this a 4. I th...          0\n",
      "3  Okay okay, I must admit, I do somewhat like Pe...          1\n",
      "4  This is the worst movie I've ever seen. Boring...          0\n",
      "5  The movie is really cool, I thought. It sticks...          1\n",
      "6  I guess this is the first movie that made me a...          1\n",
      "7  <br /><br />This movie is by far one of my fav...          1\n",
      "8  In the year 2000 (keep in mind, this is two ye...          1\n",
      "9  Walking With Dinosaurs is an amazing Documenta...          1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "Imdb_file = './Imdb_data.csv'\n",
    "\n",
    "if os.path.exists(Imdb_file):\n",
    "    \n",
    "    df = pd.read_csv(Imdb_file)\n",
    "    \n",
    "    print(df.head(10))\n",
    "\n",
    "else:\n",
    "    labels = {'pos':1, 'neg':0}\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for s in {'test', 'train'}:\n",
    "        for l in ('pos', 'neg'):\n",
    "            path = './aclImdb/%s/%s' % (s, l)\n",
    "            for file in os.listdir(path):\n",
    "                with open(os.path.join(path, file), 'r') as infile:\n",
    "                    txt = infile.read()\n",
    "\n",
    "                df = df.append([[txt, labels[l]]], ignore_index=True)\n",
    "\n",
    "    df.columns = ['review','sentiment']\n",
    "\n",
    "    np.random.seed(0)\n",
    "\n",
    "    df = df.reindex(np.random.permutation(df.index))\n",
    "    df.to_csv(Imdb_file, index=False)\n",
    "    \n",
    "    df = pd.read_csv(Imdb_file)\n",
    "    print(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "\n",
    "# set parameters:\n",
    "max_features = 5000\n",
    "maxlen = 400\n",
    "batch_size = 2 * 32\n",
    "embedding_dims = 50\n",
    "filters = 250\n",
    "\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "epochs = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "218\n",
      "189\n",
      "141\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "print(len(x_train), 'train sequences'); print(len(x_test), 'test sequences')\n",
    "\n",
    "print(len(x_train[0]))\n",
    "print(len(x_train[1]))\n",
    "print(len(x_train[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 400)\n",
      "x_test shape: (25000, 400)\n",
      "400\n",
      "400\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test  = sequence.pad_sequences( x_test, maxlen=maxlen)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print(len(x_train[0]))\n",
    "print(len(x_train[1]))\n",
    "print(len(x_train[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 영화 리뷰을 위한 CNN model 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 400, 50)           250000    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 400, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 400, 250)          37750     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 350,751\n",
      "Trainable params: 350,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 252s - loss: 0.4435 - acc: 0.7713   \n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 249s - loss: 0.2402 - acc: 0.9019   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe8ffc62a20>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Embedding(max_features, embedding_dims, input_length=maxlen))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(filters, kernel_size, padding='same', activation='relu'))\n",
    "                 \n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train 된 영화 리뷰 자료를 test 셋에 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.99%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24992/25000 [============================>.] - ETA: 0s\n",
      "test_false:  2753\n",
      "test_true:  22247\n"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict_classes(x_test)\n",
    "\n",
    "test_false = [im for im in zip(x_test,y_hat,y_test) if im[1] != im[2]]\n",
    "test_true = [im for im in zip(x_test,y_hat,y_test) if im[1] == im[2]]\n",
    "\n",
    "print('\\ntest_false: ',len(test_false))\n",
    "print('test_true: ',len(test_true))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
